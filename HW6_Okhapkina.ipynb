{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "HW6_Okhapkina.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMSSRr8wHUS9hXVoygxEvTN",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/eischaire/ML_4year/blob/master/HW6_Okhapkina.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1DRvVdmY0ctX",
        "colab_type": "text"
      },
      "source": [
        "# Assignment 6 on ML\n",
        "\n",
        "### Student: Anna Okhapkina"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tezaGNtMlguI",
        "colab_type": "code",
        "outputId": "fe99e965-74e4-4af1-ae1d-ae0308925401",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "!pip install sentencepiece"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.6/dist-packages (0.1.85)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oZj05NiVuvf_",
        "colab_type": "code",
        "outputId": "5af92957-9c33-46c4-f431-7de6d6ad0b10",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "!pip install revtok"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: revtok in /usr/local/lib/python3.6/dist-packages (0.0.3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L4xwu1d2lkdr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import sentencepiece as spm\n",
        "import torch as tt\n",
        "from torchtext import data as tt_data, datasets as tt_datasets\n",
        "import zipfile"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "puAKTJX7zTDP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tqdm import tqdm_notebook"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E-2rFazdtiyn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tqdm import trange"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hP7PH72lv0gN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch.nn as nn"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SLGwwsKxz4-r",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch.nn.functional as F\n",
        "import torch.optim as optim"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xfhFJkeq2qLV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rXZa2TQ3o6IB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NQnrFZVVoLQg",
        "colab_type": "text"
      },
      "source": [
        "## Training a SentencePiece model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5NxcAJ05n_qH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "wikiurl = tt_datasets.WikiText2.urls"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u0ddOZt5oWXK",
        "colab_type": "code",
        "outputId": "d56b4fb9-3b73-4207-e41d-2daae0e03f3d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "wikiurl"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['https://s3.amazonaws.com/research.metamind.io/wikitext/wikitext-2-v1.zip']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kD4XFIgboXij",
        "colab_type": "code",
        "outputId": "1cdf2d84-5754-4937-af9d-d99de2447140",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "!wget https://s3.amazonaws.com/research.metamind.io/wikitext/wikitext-2-v1.zip"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-02-08 17:56:19--  https://s3.amazonaws.com/research.metamind.io/wikitext/wikitext-2-v1.zip\n",
            "Resolving s3.amazonaws.com (s3.amazonaws.com)... 52.216.232.21\n",
            "Connecting to s3.amazonaws.com (s3.amazonaws.com)|52.216.232.21|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 4475746 (4.3M) [application/zip]\n",
            "Saving to: ‘wikitext-2-v1.zip.2’\n",
            "\n",
            "wikitext-2-v1.zip.2 100%[===================>]   4.27M  2.50MB/s    in 1.7s    \n",
            "\n",
            "2020-02-08 17:56:21 (2.50 MB/s) - ‘wikitext-2-v1.zip.2’ saved [4475746/4475746]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yP6Wlw8jod8T",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "with zipfile.ZipFile('wikitext-2-v1.zip', 'r') as zip_files:\n",
        "  zip_files.extractall('wikitext2')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "87ItCpNdozOj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "with open(os.path.join('wikitext2', 'wikitext-2', 'wiki.test.tokens'), 'r') as f:\n",
        "  test_file = f.read()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Re-s5HpUpJJP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_path = os.path.join('wikitext2', 'wikitext-2', 'wiki.train.tokens')\n",
        "val_path = os.path.join('wikitext2', 'wikitext-2', 'wiki.valid.tokens')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "II4bzZklrJAc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "with open(train_path, 'r') as f:\n",
        "  train_file = f.read()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Oo0y9btarQGJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "with open(val_path, 'r') as f:\n",
        "  val_file = f.read()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8g9IfND4rU3N",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sp_model_data = train_file + test_file + val_file\n",
        "with open('sp_train.txt', 'w') as k:\n",
        "  k.writelines(sp_model_data)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s0R1kOFDrpiV",
        "colab_type": "code",
        "outputId": "7dc89d4b-4b07-4a34-ff33-56d58f5f7a86",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "spm.SentencePieceTrainer.Train('--input=sp_train.txt --model_prefix=sp_model --model_type=BPE --vocab_size=15000')"
      ],
      "execution_count": 241,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 241
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6LHrzDMFsQY9",
        "colab_type": "code",
        "outputId": "13c4720d-0169-48ed-bc35-361d1a5fc14a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "sp = spm.SentencePieceProcessor()\n",
        "sp.load('sp_model.model')"
      ],
      "execution_count": 242,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 242
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PG--WvyGsqsA",
        "colab_type": "text"
      },
      "source": [
        "## Preprocessing the dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6dei7NBcsesF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "spm_pipeline = tt_data.Pipeline(convert_token=sp.encode_as_pieces)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tjdzQ9kltH57",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "check_tokens = [' Hello ', ' Mom ', ' greetings ', ' from ', ' me ', ' How ', ' are ', ' you ', ' today ', ' ? ']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xw4iYk7Ds9GJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def merge_lists(inp):\n",
        "  merged = []\n",
        "  for item in inp:\n",
        "    merged += item\n",
        "  return merged"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9OCRTFbEtXJB",
        "colab_type": "code",
        "outputId": "67b93f50-96d0-4940-d378-36835e7429f7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 272
        }
      },
      "source": [
        "merge_lists(spm_pipeline(check_tokens))"
      ],
      "execution_count": 247,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['▁Hell',\n",
              " 'o',\n",
              " '▁M',\n",
              " 'om',\n",
              " '▁g',\n",
              " 'reet',\n",
              " 'ings',\n",
              " '▁from',\n",
              " '▁me',\n",
              " '▁How',\n",
              " '▁are',\n",
              " '▁you',\n",
              " '▁today',\n",
              " '▁',\n",
              " '?']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 247
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e-v6PmfXtazW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "TEXT = tt_data.ReversibleField(use_vocab=True, \n",
        "             preprocessing = lambda x: merge_lists(spm_pipeline(x)),             \n",
        "             init_token='<start>', eos_token='<end>',\n",
        "             is_target=True\n",
        "            )"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W-lrNVc52E6H",
        "colab_type": "code",
        "outputId": "fb0b0e8f-8b7d-4a82-d926-e8567e02484c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 272
        }
      },
      "source": [
        "TEXT.preprocess(check_tokens)"
      ],
      "execution_count": 249,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['▁Hell',\n",
              " 'o',\n",
              " '▁M',\n",
              " 'om',\n",
              " '▁g',\n",
              " 'reet',\n",
              " 'ings',\n",
              " '▁from',\n",
              " '▁me',\n",
              " '▁How',\n",
              " '▁are',\n",
              " '▁you',\n",
              " '▁today',\n",
              " '▁',\n",
              " '?']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 249
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m0tC3_BsnY_5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dryb4i3_to9y",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "1ba034eb-d9b1-4678-b328-7ae5ded961cb"
      },
      "source": [
        "train, valid, test = tt_datasets.WikiText2.splits(TEXT)"
      ],
      "execution_count": 251,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4chqsd28tqOV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "TEXT.build_vocab(train, valid, test, min_freq=5)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2Zc8uVi3viwi",
        "colab_type": "code",
        "outputId": "40c56ceb-d16a-4833-b399-bec15a568cce",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 357
        }
      },
      "source": [
        "TEXT.vocab.itos[:20]"
      ],
      "execution_count": 253,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[' UNK ',\n",
              " '<pad>',\n",
              " '<start>',\n",
              " '<end>',\n",
              " '▁',\n",
              " '▁the',\n",
              " '<',\n",
              " '>',\n",
              " '▁,',\n",
              " '▁.',\n",
              " '▁unk',\n",
              " '▁of',\n",
              " '▁and',\n",
              " '▁@',\n",
              " '▁in',\n",
              " '▁a',\n",
              " 'e',\n",
              " '▁to',\n",
              " 'os',\n",
              " '▁=']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 253
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-ZOFvTvHbrfi",
        "colab_type": "code",
        "outputId": "da8dfb47-0c9d-451d-c19b-04791dd821bf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "len(TEXT.vocab.itos)"
      ],
      "execution_count": 254,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "12202"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 254
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fS7V8Hukv7xS",
        "colab_type": "text"
      },
      "source": [
        "## Defining the NN model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VFzX0d1OvmAd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class MyModel(nn.Module):\n",
        "    \n",
        "    def __init__(self, vocab_size, target_vocab_size, embed_size, hidden_size):\n",
        "        super(MyModel, self).__init__()\n",
        "        self.embedding = nn.Embedding(vocab_size, embed_size)\n",
        "        \n",
        "        self.rnn = nn.LSTM(input_size=embed_size,\n",
        "                           hidden_size=hidden_size,\n",
        "                           bidirectional=True,\n",
        "                          )\n",
        "        \n",
        "        self.fc = nn.Linear(hidden_size * 2, target_vocab_size)\n",
        "        \n",
        "        self.init_weights()\n",
        "        \n",
        "    def init_weights(self):\n",
        "        nn.init.uniform_(self.embedding.weight)\n",
        "        nn.init.xavier_uniform_(self.fc.weight)\n",
        "        nn.init.zeros_(self.fc.bias)\n",
        "\n",
        "    def forward(self, text):\n",
        "        \n",
        "        \n",
        "        x = text\n",
        "        \n",
        "        x = self.embedding(x)\n",
        "\n",
        "            \n",
        "        x, _ = self.rnn(x)\n",
        "        \n",
        "        x = self.fc(x)\n",
        "        return x.transpose(1,2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zJF4XQqbw7D3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# tt.cuda.empty_cache()\n",
        "\n",
        "batch_size = 32\n",
        "\n",
        "model = MyModel(vocab_size=len(TEXT.vocab.itos),\n",
        "                target_vocab_size=len(TEXT.vocab.itos),\n",
        "                embed_size=100,\n",
        "                hidden_size=128,\n",
        "               )\n",
        "\n",
        "train_iterator, valid_iterator, test_iterator = tt_data.BPTTIterator.splits(\n",
        "    (train, valid, test),\n",
        "    bptt_len=30,\n",
        "    device=tt.device('cuda'),\n",
        "    batch_size=batch_size,\n",
        "    shuffle=False,\n",
        "    # sort_key=lambda x: len(x.text),\n",
        "    # sort_within_batch=True\n",
        ")\n",
        "\n",
        "optimizer = optim.Adam(model.parameters())\n",
        "# scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, patience=5, verbose=True, cooldown=5)\n",
        "scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=5)\n",
        "\n",
        "# padding does not count into loss\n",
        "# criterion = nn.CrossEntropyLoss(ignore_index=1)\n",
        "criterion = nn.CrossEntropyLoss()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zvp1NmmJvdfC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tqdm import tqdm"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3mmTtZjFzjQC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def _train_epoch(model, iterator, optimizer, criterion, curr_epoch):\n",
        "\n",
        "    # model.cuda()\n",
        "    # criterion.cuda()\n",
        "\n",
        "    model.train()\n",
        "\n",
        "    running_loss = 0\n",
        "\n",
        "    n_batches = len(iterator)\n",
        "    # iterator = tqdm_notebook(iterator, total=n_batches, desc='epoch %d' % (curr_epoch), leave=True)\n",
        "    iterator = tqdm(iterator) #, total=n_batches, desc='epoch %d' % (curr_epoch), leave=True)\n",
        "\n",
        "    for i, batch in enumerate(iterator):\n",
        "        optimizer.zero_grad()\n",
        "        x = batch.text.to(tt.device('cuda'))\n",
        "        pred = model(x)\n",
        "        loss = criterion(pred, batch.target)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "  \n",
        "        curr_loss = loss.data.cpu().detach().item()\n",
        "        \n",
        "        loss_smoothing = i / (i+1)\n",
        "        running_loss = loss_smoothing * running_loss + (1 - loss_smoothing) * curr_loss\n",
        "\n",
        "        iterator.set_postfix(loss='%.5f' % running_loss)\n",
        "\n",
        "    return running_loss\n",
        "\n",
        "\n",
        "def _test_epoch(model, iterator, criterion):\n",
        "\n",
        "    # model.cuda()\n",
        "    # criterion.cuda()\n",
        "\n",
        "    model.eval()\n",
        "    epoch_loss = 0\n",
        "\n",
        "    n_batches = len(iterator)\n",
        "    with tt.no_grad():\n",
        "        for batch in iterator:\n",
        "            pred = model(batch.text)\n",
        "            loss = criterion(pred, batch.target)\n",
        "            epoch_loss += loss.data.item()\n",
        "\n",
        "    return epoch_loss / n_batches\n",
        "\n",
        "\n",
        "def nn_train(model, train_iterator, valid_iterator, criterion, optimizer, n_epochs=100,\n",
        "          scheduler=None, early_stopping=0):\n",
        "    model.to(tt.device('cuda'))\n",
        "    criterion.to(tt.device('cuda'))\n",
        "    # optimizer.cuda()\n",
        "    prev_loss = 100500\n",
        "    es_epochs = 0\n",
        "    best_epoch = None\n",
        "    history = pd.DataFrame()\n",
        "\n",
        "    for epoch in range(n_epochs):\n",
        "        train_loss = _train_epoch(model, train_iterator, optimizer, criterion, epoch)\n",
        "        valid_loss = _test_epoch(model, valid_iterator, criterion)\n",
        "\n",
        "        valid_loss = valid_loss\n",
        "        print('validation loss %.5f' % valid_loss)\n",
        "\n",
        "        record = {'epoch': epoch, 'train_loss': train_loss, 'valid_loss': valid_loss}\n",
        "        history = history.append(record, ignore_index=True)\n",
        "\n",
        "        if early_stopping > 0:\n",
        "            if valid_loss > prev_loss:\n",
        "                es_epochs += 1\n",
        "            else:\n",
        "                es_epochs = 0\n",
        "\n",
        "            if es_epochs >= early_stopping:\n",
        "                best_epoch = history[history.valid_loss == history.valid_loss.min()].iloc[0]\n",
        "                print('Early stopping! best epoch: %d val %.5f' % (best_epoch['epoch'], best_epoch['valid_loss']))\n",
        "                break\n",
        "\n",
        "            prev_loss = min(prev_loss, valid_loss)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VOwgdNsOwtWz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# if tqdm._instances:\n",
        "#   for instance in list(tqdm._instances): \n",
        "#     tqdm._decr_instances(instance)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eo0JkR2b0ULU",
        "colab_type": "code",
        "outputId": "14052b96-bc4d-41cf-afbb-14cb6f89c0c5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 357
        }
      },
      "source": [
        "nn_train(model, train_iterator, valid_iterator, criterion, optimizer, scheduler=scheduler, \n",
        "        n_epochs=10, early_stopping=3)"
      ],
      "execution_count": 260,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 3012/3012 [01:07<00:00, 44.60it/s, loss=3.38171]\n",
            "  0%|          | 0/3012 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "validation loss 1.71028\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 3012/3012 [01:07<00:00, 44.83it/s, loss=1.05934]\n",
            "  0%|          | 0/3012 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "validation loss 0.66705\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 3012/3012 [01:07<00:00, 44.65it/s, loss=0.41542]\n",
            "  0%|          | 0/3012 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "validation loss 0.37006\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 3012/3012 [01:07<00:00, 44.55it/s, loss=0.24044]\n",
            "  0%|          | 0/3012 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "validation loss 0.27022\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 3012/3012 [01:07<00:00, 44.48it/s, loss=0.18293]\n",
            "  0%|          | 0/3012 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "validation loss 0.23259\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 3012/3012 [01:07<00:00, 44.46it/s, loss=0.15746]\n",
            "  0%|          | 0/3012 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "validation loss 0.21622\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 3012/3012 [01:07<00:00, 44.49it/s, loss=0.14151]\n",
            "  0%|          | 0/3012 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "validation loss 0.21162\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 3012/3012 [01:07<00:00, 44.53it/s, loss=0.12892]\n",
            "  0%|          | 0/3012 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "validation loss 0.21089\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 3012/3012 [01:07<00:00, 44.61it/s, loss=0.11794]\n",
            "  0%|          | 0/3012 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "validation loss 0.21507\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 3012/3012 [01:07<00:00, 44.72it/s, loss=0.10800]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "validation loss 0.21872\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DOYRogh52nLj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def reverse(self, batch):\n",
        "    if not self.batch_first:\n",
        "        batch = batch.t()\n",
        "    with tt.cuda.device_of(batch):\n",
        "        batch = batch.tolist()\n",
        "    batch = [[self.vocab.itos[ind] for ind in ex] for ex in batch]  # denumericalize\n",
        "    def trim(s, t):\n",
        "        sentence = []\n",
        "        for w in s:\n",
        "            if w == t:\n",
        "                break\n",
        "            sentence.append(w)\n",
        "        return sentence\n",
        "\n",
        "    batch = [trim(ex, self.eos_token) for ex in batch]  # trim past frst eos\n",
        "\n",
        "    def filter_special(tok):\n",
        "        return tok not in (self.init_token, self.pad_token)\n",
        "\n",
        "    batch = [filter(filter_special, ex) for ex in batch]\n",
        "\n",
        "    return [' '.join(ex) for ex in batch]\n",
        "\n",
        "TEXT.reverse = reverse"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-vp_x1BOCK6E",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "a1d58fef-db5f-4602-bcd6-25c019d645ae"
      },
      "source": [
        "for batch in test_iterator:\n",
        "    pred = model(batch.text)\n",
        "    pred = tt.softmax(pred, dim=1)\n",
        "    pred = tt.argmax(pred, dim=1)\n",
        "    pred_text = TEXT.reverse(TEXT, pred)\n",
        "    batch_text = TEXT.reverse(TEXT, batch.text)\n",
        "    true_text = TEXT.reverse(TEXT, batch.target)\n",
        "\n",
        "    pred_text = reverse(TEXT, pred)    \n",
        "    batch_text = reverse(TEXT, batch.text)\n",
        "    true_text = reverse(TEXT, batch.target)\n",
        "\n",
        "    for i in range(len(true_text)):\n",
        "        print(i)\n",
        "        print('batch text: ', batch_text[i])\n",
        "        print('true text: ', true_text[i])\n",
        "        print('pred text: ', pred_text[i])\n",
        "        print()\n",
        "        \n",
        "    break"
      ],
      "execution_count": 262,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "batch text:  ▁ < e os > ▁= ▁Robert ▁ < ▁unk ▁ > ▁= ▁ < e os > ▁ < e os > ▁Robert ▁ < ▁unk ▁ > ▁is\n",
            "true text:  < e os > ▁= ▁Robert ▁ < ▁unk ▁ > ▁= ▁ < e os > ▁ < e os > ▁Robert ▁ < ▁unk ▁ > ▁is ▁an\n",
            "pred text:  < e os > ▁= ▁Robert ▁ < ▁unk ▁ > ▁= ▁ < e os > ▁ < e os > ▁Robert ▁ < ▁unk ▁ > ▁is ▁a\n",
            "\n",
            "batch text:  ▁ > ▁Rock ▁and ▁Beach ▁ < ▁unk ▁ > ▁ < ▁unk ▁ > ▁, ▁as ▁well ▁as ▁the ▁iconic ▁music ▁videos ▁of ▁songs ▁such ▁as ▁The ▁Beach ▁Boys\n",
            "true text:  > ▁Rock ▁and ▁Beach ▁ < ▁unk ▁ > ▁ < ▁unk ▁ > ▁, ▁as ▁well ▁as ▁the ▁iconic ▁music ▁videos ▁of ▁songs ▁such ▁as ▁The ▁Beach ▁Boys ▁'\n",
            "pred text:  > ▁Rock ▁and ▁Beach ▁ < ▁unk ▁ > ▁ < ▁unk ▁ > ▁, ▁as ▁well ▁as ▁the ▁iconic ▁music ▁videos ▁of ▁songs ▁such ▁as ▁The ▁Beach ▁Boys ▁of\n",
            "\n",
            "batch text:  ▁ ions ▁records ▁for ▁both ▁career ▁touchdown ▁and ▁single ▁@ ▁- ▁@ ▁season ▁touchdowns ▁. ▁He ▁had ▁also ▁been ▁a ▁Michigan ▁High ▁School ▁Athletic ▁Association ▁( ▁ < ▁unk ▁\n",
            "true text:  ions ▁records ▁for ▁both ▁career ▁touchdown ▁and ▁single ▁@ ▁- ▁@ ▁season ▁touchdowns ▁. ▁He ▁had ▁also ▁been ▁a ▁Michigan ▁High ▁School ▁Athletic ▁Association ▁( ▁ < ▁unk ▁ >\n",
            "pred text:  ions ▁records ▁for ▁both ▁career ▁touchdown ▁and ▁single ▁@ ▁- ▁@ ▁season ▁touchdowns ▁. ▁He ▁had ▁also ▁been ▁a ▁Michigan ▁High ▁School ▁Athletic ▁Association ▁( ▁ < ▁unk ▁ >\n",
            "\n",
            "batch text:  ▁its ▁force ▁, ▁less ▁C ▁Company ▁, ▁just ▁north ▁of ▁Lake ▁U ▁@ ▁- ▁@ ▁p ▁ < ▁unk ▁ > ▁and ▁the ▁hills ▁there ▁covering ▁the ▁northern ▁road ▁into\n",
            "true text:  ▁force ▁, ▁less ▁C ▁Company ▁, ▁just ▁north ▁of ▁Lake ▁U ▁@ ▁- ▁@ ▁p ▁ < ▁unk ▁ > ▁and ▁the ▁hills ▁there ▁covering ▁the ▁northern ▁road ▁into ▁\n",
            "pred text:  ▁force ▁, ▁less ▁C ▁Company ▁, ▁just ▁north ▁of ▁Lake ▁U ▁@ ▁- ▁@ ▁p ▁ < ▁unk ▁ > ▁and ▁the ▁hills ▁there ▁covering ▁the ▁northern ▁road ▁into ▁the\n",
            "\n",
            "batch text:  ▁a ter ▁rest rial ▁life ▁, ▁criticism ▁of ▁organized ▁religion ▁, ▁the ▁9 ▁/ ▁11 ▁Truth ▁movement ▁, ▁cann ▁ab ▁is ▁use ▁and ▁sexual ▁inter ▁course ▁. ▁ < e\n",
            "true text:  ter ▁rest rial ▁life ▁, ▁criticism ▁of ▁organized ▁religion ▁, ▁the ▁9 ▁/ ▁11 ▁Truth ▁movement ▁, ▁cann ▁ab ▁is ▁use ▁and ▁sexual ▁inter ▁course ▁. ▁ < e os\n",
            "pred text:  ter ▁rest rial ▁life ▁, ▁criticism ▁of ▁organized ▁religion ▁, ▁the ▁9 ▁/ ▁11 ▁parks ▁movement ▁, ▁cann ▁ab ▁is ▁use ▁and ▁sexual ▁inter ▁course ▁. ▁ < e os\n",
            "\n",
            "batch text:  ▁The ▁German ▁Ka ▁is er ▁Friedrich ▁III ▁, ▁laid ▁down ▁in ▁1895 ▁, ▁was ▁the ▁first ▁ship ▁to ▁benefit ▁from ▁the ▁new ▁' ▁ < ▁unk ▁ > ▁armor ▁'\n",
            "true text:  ▁German ▁Ka ▁is er ▁Friedrich ▁III ▁, ▁laid ▁down ▁in ▁1895 ▁, ▁was ▁the ▁first ▁ship ▁to ▁benefit ▁from ▁the ▁new ▁' ▁ < ▁unk ▁ > ▁armor ▁' ▁and\n",
            "pred text:  ▁German ▁Ka ▁is er ▁Friedrich ▁III ▁, ▁laid ▁down ▁in ▁1895 ▁, ▁was ▁the ▁first ▁ship ▁to ▁benefit ▁from ▁the ▁new ▁' ▁ < ▁unk ▁ > ▁armor ▁' ▁s\n",
            "\n",
            "batch text:  ▁w ▁ ield ▁ed ▁language ▁as ▁an ▁almost ▁supernatural ▁force ▁\" ▁, ▁drawing ▁attention ▁to ▁Nazi ▁hun ▁ter ▁Em ▁man ▁u el ▁ < ▁unk ▁ > ▁' ▁s ▁warning\n",
            "true text:  ▁ ield ▁ed ▁language ▁as ▁an ▁almost ▁supernatural ▁force ▁\" ▁, ▁drawing ▁attention ▁to ▁Nazi ▁hun ▁ter ▁Em ▁man ▁u el ▁ < ▁unk ▁ > ▁' ▁s ▁warning ▁from\n",
            "pred text:  ▁ ield ▁ed ▁language ▁as ▁an ▁almost ▁supernatural ▁force ▁\" ▁, ▁drawing ▁attention ▁to ▁Nazi ▁hun ▁ter ▁Em ▁man ▁u el ▁ < ▁unk ▁ > ▁' ▁s ▁warning ▁about\n",
            "\n",
            "batch text:  ▁ancestors ▁differ ▁from ▁ < ▁unk ▁ > ▁like ▁ < ▁unk ▁ > ▁in ▁that ▁their ▁skulls ▁were ▁also ▁built ▁to ▁with ▁st ▁and ▁tension ▁. ▁This ▁tension ▁would\n",
            "true text:  ▁differ ▁from ▁ < ▁unk ▁ > ▁like ▁ < ▁unk ▁ > ▁in ▁that ▁their ▁skulls ▁were ▁also ▁built ▁to ▁with ▁st ▁and ▁tension ▁. ▁This ▁tension ▁would ▁have\n",
            "pred text:  ▁differ ▁from ▁ < ▁unk ▁ > ▁like ▁ < ▁unk ▁ > ▁in ▁that ▁their ▁skulls ▁were ▁also ▁built ▁to ▁with ▁st ▁and ▁Byron ▁. ▁This ▁tension ▁would ▁have\n",
            "\n",
            "batch text:  ▁of ▁his ▁pit ▁c hes ▁, ▁he ▁established ▁himself ▁as ▁an ▁elite ▁high ▁school ▁prospect ▁in ▁2006 ▁when ▁he ▁posted ▁a ▁13 ▁– ▁0 ▁record ▁with ▁an ▁earned ▁run ▁average\n",
            "true text:  ▁his ▁pit ▁c hes ▁, ▁he ▁established ▁himself ▁as ▁an ▁elite ▁high ▁school ▁prospect ▁in ▁2006 ▁when ▁he ▁posted ▁a ▁13 ▁– ▁0 ▁record ▁with ▁an ▁earned ▁run ▁average ▁(\n",
            "pred text:  ▁his ▁pit ▁c hes ▁, ▁he ▁established ▁himself ▁as ▁an ▁elite ▁high ▁school ▁prospect ▁in ▁2006 ▁when ▁he ▁posted ▁a ▁13 ▁– ▁0 ▁record ▁with ▁an ▁earned ▁run ▁average ▁of\n",
            "\n",
            "batch text:  ▁. ▁In ▁following ▁years ▁, ▁ < ▁unk ▁ > ▁became ▁perhaps ▁the ▁most ▁important ▁of ▁ < ▁unk ▁ > ▁' ▁s ▁early ▁champions ▁; ▁she ▁arranged ▁this ▁showing\n",
            "true text:  ▁In ▁following ▁years ▁, ▁ < ▁unk ▁ > ▁became ▁perhaps ▁the ▁most ▁important ▁of ▁ < ▁unk ▁ > ▁' ▁s ▁early ▁champions ▁; ▁she ▁arranged ▁this ▁showing ▁—\n",
            "pred text:  ▁In ▁following ▁years ▁, ▁ < ▁unk ▁ > ▁became ▁perhaps ▁the ▁most ▁important ▁of ▁ < ▁unk ▁ > ▁' ▁s ▁early ▁champions ▁; ▁she ▁arranged ▁this ▁showing ▁it\n",
            "\n",
            "batch text:  ▁d s ▁were ▁better ▁than ▁even ▁that ▁we ▁would ▁have ▁to ▁leave ▁Mogadishu ▁under ▁less ▁than ▁favorable ▁circumstances ▁. ▁\" ▁Ambassador ▁Bishop ▁understood ▁from ▁his ▁past ▁experiences ▁in ▁Be ▁ir\n",
            "true text:  s ▁were ▁better ▁than ▁even ▁that ▁we ▁would ▁have ▁to ▁leave ▁Mogadishu ▁under ▁less ▁than ▁favorable ▁circumstances ▁. ▁\" ▁Ambassador ▁Bishop ▁understood ▁from ▁his ▁past ▁experiences ▁in ▁Be ▁ir ▁ut\n",
            "pred text:  s ▁were ▁better ▁than ▁even ▁that ▁we ▁would ▁have ▁to ▁leave ▁Mogadishu ▁under ▁less ▁than ▁favorable ▁circumstances ▁. ▁\" ▁Ambassador ▁Bishop ▁kicked ▁from ▁his ▁past ▁experiences ▁in ▁Be ▁ir a\n",
            "\n",
            "batch text:  ▁at ▁the ▁top ▁of ▁the ▁Billboard ▁Top ▁Latin ▁Albums ▁for ▁the ▁week ▁ending ▁22 ▁October ▁2011 ▁, ▁and ▁remained ▁at ▁that ▁position ▁the ▁following ▁week ▁. ▁It ▁was ▁the ▁third\n",
            "true text:  ▁the ▁top ▁of ▁the ▁Billboard ▁Top ▁Latin ▁Albums ▁for ▁the ▁week ▁ending ▁22 ▁October ▁2011 ▁, ▁and ▁remained ▁at ▁that ▁position ▁the ▁following ▁week ▁. ▁It ▁was ▁the ▁third ▁album\n",
            "pred text:  ▁the ▁top ▁of ▁the ▁Billboard ▁Top ▁Latin ▁Albums ▁for ▁the ▁week ▁ending ▁22 ▁October ▁2011 ▁, ▁and ▁remained ▁at ▁that ▁position ▁the ▁following ▁week ▁. ▁It ▁was ▁the ▁third ▁single\n",
            "\n",
            "batch text:  ▁and ▁the ▁JTWC ▁estimated ▁peak ▁1 ▁minute ▁winds ▁of ▁185 ▁km ▁/ ▁h ▁( ▁115 ▁mph ▁) ▁on ▁September ▁21 ▁, ▁after ▁ < ▁unk ▁ > ▁@ ▁- ▁@\n",
            "true text:  ▁the ▁JTWC ▁estimated ▁peak ▁1 ▁minute ▁winds ▁of ▁185 ▁km ▁/ ▁h ▁( ▁115 ▁mph ▁) ▁on ▁September ▁21 ▁, ▁after ▁ < ▁unk ▁ > ▁@ ▁- ▁@ ▁\n",
            "pred text:  ▁the ▁JTWC ▁estimated ▁peak ▁1 ▁minute ▁winds ▁of ▁185 ▁km ▁/ ▁h ▁( ▁115 ▁mph ▁) ▁on ▁September ▁21 ▁, ▁after ▁ < ▁unk ▁ > ▁@ ▁- ▁@ ▁\n",
            "\n",
            "batch text:  ▁poor ▁supply ▁app ▁ar ▁at us ▁. ▁Mack ▁completely ▁ < ▁unk ▁ > ▁the ▁French ▁ < ▁unk ▁ > ▁and ▁scattered ▁his ▁forces ▁; ▁as ▁the ▁French ▁defeated\n",
            "true text:  ▁supply ▁app ▁ar ▁at us ▁. ▁Mack ▁completely ▁ < ▁unk ▁ > ▁the ▁French ▁ < ▁unk ▁ > ▁and ▁scattered ▁his ▁forces ▁; ▁as ▁the ▁French ▁defeated ▁each\n",
            "pred text:  ▁supply ▁app ▁ar ▁at us ▁. ▁Mack ▁completely ▁ < ▁unk ▁ > ▁the ▁French ▁ < ▁unk ▁ > ▁and ▁scattered ▁his ▁forces ▁; ▁as ▁the ▁French ▁defeated ▁.\n",
            "\n",
            "batch text:  ▁and ▁entered ▁the ▁Royal ▁R ▁ umble ▁as ▁the ▁ # ▁29 ▁entry ▁, ▁the ▁second ▁to ▁last ▁competitor ▁to ▁enter ▁the ▁match ▁. ▁He ▁eliminated ▁Matt ▁Hardy ▁and ▁The\n",
            "true text:  ▁entered ▁the ▁Royal ▁R ▁ umble ▁as ▁the ▁ # ▁29 ▁entry ▁, ▁the ▁second ▁to ▁last ▁competitor ▁to ▁enter ▁the ▁match ▁. ▁He ▁eliminated ▁Matt ▁Hardy ▁and ▁The ▁World\n",
            "pred text:  ▁entered ▁the ▁Royal ▁R ▁ umble ▁as ▁the ▁ # ▁29 ▁entry ▁, ▁the ▁second ▁to ▁last ▁competitor ▁to ▁enter ▁the ▁match ▁. ▁He ▁eliminated ▁Matt ▁Hardy ▁and ▁The ▁Guardian\n",
            "\n",
            "batch text:  ▁six ▁@ ▁- ▁@ ▁month ▁hunting ▁susp ▁ens ion ▁. ▁ < e os > ▁As ▁of ▁July ▁2016 ▁, ▁ < ▁unk ▁ > ▁' ▁s ▁eldest ▁son ▁,\n",
            "true text:  ▁@ ▁- ▁@ ▁month ▁hunting ▁susp ▁ens ion ▁. ▁ < e os > ▁As ▁of ▁July ▁2016 ▁, ▁ < ▁unk ▁ > ▁' ▁s ▁eldest ▁son ▁, ▁\n",
            "pred text:  ▁@ ▁- ▁@ ▁month ▁hunting ▁susp ▁ens ion ▁. ▁ < e os > ▁As ▁of ▁July ▁2016 ▁, ▁ < ▁unk ▁ > ▁' ▁s ▁eldest ▁son ▁, ▁and\n",
            "\n",
            "batch text:  ▁\" ▁the ▁story ▁feels ▁tr ▁unc ▁at ed ▁and ▁rushed ▁\" ▁ < e os > ▁The ▁Mir ▁r or ▁' ▁s ▁Jon ▁Cooper ▁also ▁praised ▁Coleman ▁and ▁the ▁new\n",
            "true text:  ▁the ▁story ▁feels ▁tr ▁unc ▁at ed ▁and ▁rushed ▁\" ▁ < e os > ▁The ▁Mir ▁r or ▁' ▁s ▁Jon ▁Cooper ▁also ▁praised ▁Coleman ▁and ▁the ▁new ▁side\n",
            "pred text:  ▁the ▁story ▁feels ▁tr ▁unc ▁at ed ▁and ▁rushed ▁\" ▁ < e os > ▁The ▁regiment ▁r or ▁' ▁s ▁Jon ▁Cooper ▁also ▁praised ▁Coleman ▁and ▁the ▁new ▁song\n",
            "\n",
            "batch text:  ▁ > ▁) ▁, ▁and ▁can ▁collect ▁pop ▁c ▁orn ▁and ▁g ▁ um ▁along ▁the ▁way ▁or ▁get ▁the ▁latter ▁from ▁ < ▁unk ▁ > ▁ < ▁unk\n",
            "true text:  > ▁) ▁, ▁and ▁can ▁collect ▁pop ▁c ▁orn ▁and ▁g ▁ um ▁along ▁the ▁way ▁or ▁get ▁the ▁latter ▁from ▁ < ▁unk ▁ > ▁ < ▁unk ▁\n",
            "pred text:  > ▁) ▁, ▁and ▁can ▁collect ▁pop ▁c ▁orn ▁and ▁g ▁ um ▁along ▁the ▁way ▁or ▁get ▁the ▁latter ▁from ▁ < ▁unk ▁ > ▁ < ▁unk ▁\n",
            "\n",
            "batch text:  ▁damaged ▁. ▁The ▁surviving ▁features ▁display ▁a ▁ < ▁unk ▁ > ▁and ▁ < ▁unk ▁ > ▁around ▁the ▁nose ▁and ▁ < ▁unk ▁ > ▁. ▁The ▁head\n",
            "true text:  ▁. ▁The ▁surviving ▁features ▁display ▁a ▁ < ▁unk ▁ > ▁and ▁ < ▁unk ▁ > ▁around ▁the ▁nose ▁and ▁ < ▁unk ▁ > ▁. ▁The ▁head ▁displays\n",
            "pred text:  ▁. ▁The ▁surviving ▁features ▁display ▁a ▁ < ▁unk ▁ > ▁and ▁ < ▁unk ▁ > ▁around ▁the ▁nose ▁and ▁ < ▁unk ▁ > ▁. ▁The ▁head ▁of\n",
            "\n",
            "batch text:  ▁he ▁ ’ ▁s ▁about ▁as ▁competitive ▁of ▁a ▁guy ▁as ▁I ▁know ▁. ▁We ▁would ▁get ▁into ▁it ▁constantly ▁, ▁whether ▁playing ▁two ▁@ ▁- ▁@ ▁on ▁@ ▁-\n",
            "true text:  ▁ ’ ▁s ▁about ▁as ▁competitive ▁of ▁a ▁guy ▁as ▁I ▁know ▁. ▁We ▁would ▁get ▁into ▁it ▁constantly ▁, ▁whether ▁playing ▁two ▁@ ▁- ▁@ ▁on ▁@ ▁- ▁@\n",
            "pred text:  ▁ ’ ▁s ▁about ▁as ▁competitive ▁of ▁a ▁guy ▁as ▁I ▁know ▁. ▁We ▁would ▁get ▁into ▁it ▁constantly ▁, ▁whether ▁playing ▁two ▁@ ▁- ▁@ ▁on ▁@ ▁- ▁@\n",
            "\n",
            "batch text:  ▁view ▁of ▁Angela ▁— ▁\" ▁the ▁ < ▁unk ▁ > ▁, ▁fantasy ▁@ ▁- ▁@ ▁driven ▁exterior ▁of ▁the ▁' ▁American ▁Beauty ▁' ▁\" ▁— ▁as ▁it ▁burns ▁away\n",
            "true text:  ▁of ▁Angela ▁— ▁\" ▁the ▁ < ▁unk ▁ > ▁, ▁fantasy ▁@ ▁- ▁@ ▁driven ▁exterior ▁of ▁the ▁' ▁American ▁Beauty ▁' ▁\" ▁— ▁as ▁it ▁burns ▁away ▁to\n",
            "pred text:  ▁of ▁Angela ▁— ▁\" ▁the ▁ < ▁unk ▁ > ▁, ▁fantasy ▁@ ▁- ▁@ ▁driven ▁exterior ▁of ▁the ▁' ▁American ▁championship ▁' ▁\" ▁— ▁as ▁it ▁burns ▁away ▁from\n",
            "\n",
            "batch text:  ▁] ▁and ▁ < ▁unk ▁ > ▁real ▁\" ▁characters ▁. ▁ < ▁unk ▁ > ▁, ▁while ▁critical ▁of ▁many ▁of ▁ < ▁unk ▁ > ▁and ▁Ball ▁'\n",
            "true text:  ▁and ▁ < ▁unk ▁ > ▁real ▁\" ▁characters ▁. ▁ < ▁unk ▁ > ▁, ▁while ▁critical ▁of ▁many ▁of ▁ < ▁unk ▁ > ▁and ▁Ball ▁' ▁s\n",
            "pred text:  ▁and ▁ < ▁unk ▁ > ▁real ▁\" ▁characters ▁. ▁ < ▁unk ▁ > ▁, ▁while ▁critical ▁of ▁many ▁of ▁ < ▁unk ▁ > ▁and ▁Ball ▁' ▁s\n",
            "\n",
            "batch text:  ▁cool ▁his ▁wine ▁, ▁which ▁had ▁already ▁been ▁ < ▁unk ▁ > ▁, ▁and ▁su ▁c c ▁ umb ▁ed ▁within ▁minutes ▁. ▁After ▁the ▁death ▁of ▁ <\n",
            "true text:  ▁his ▁wine ▁, ▁which ▁had ▁already ▁been ▁ < ▁unk ▁ > ▁, ▁and ▁su ▁c c ▁ umb ▁ed ▁within ▁minutes ▁. ▁After ▁the ▁death ▁of ▁ < ▁unk\n",
            "pred text:  ▁his ▁wine ▁, ▁which ▁had ▁already ▁been ▁ < ▁unk ▁ > ▁, ▁and ▁su ▁c c ▁ umb ▁ed ▁within ▁minutes ▁. ▁After ▁the ▁death ▁of ▁ < ▁unk\n",
            "\n",
            "batch text:  ▁The ▁first ▁text ▁to ▁suggest ▁that ▁ < ▁unk ▁ > ▁ordered ▁the ▁execution ▁of ▁an ▁ < ▁unk ▁ > ▁is ▁a ▁letter ▁by ▁Clement ▁to ▁the ▁ <\n",
            "true text:  ▁first ▁text ▁to ▁suggest ▁that ▁ < ▁unk ▁ > ▁ordered ▁the ▁execution ▁of ▁an ▁ < ▁unk ▁ > ▁is ▁a ▁letter ▁by ▁Clement ▁to ▁the ▁ < ▁unk\n",
            "pred text:  ▁first ▁text ▁to ▁suggest ▁that ▁ < ▁unk ▁ > ▁ordered ▁the ▁execution ▁of ▁an ▁ < ▁unk ▁ > ▁is ▁a ▁letter ▁by ▁Clement ▁to ▁the ▁ < ▁unk\n",
            "\n",
            "batch text:  ▁the ▁city ▁, ▁including ▁its ▁very ▁first ▁chapel ▁( ▁now ▁a ▁museum ▁) ▁in ▁P ▁un t ▁a ▁, ▁ < ▁unk ▁ > ▁. ▁ < ▁unk ▁ >\n",
            "true text:  ▁city ▁, ▁including ▁its ▁very ▁first ▁chapel ▁( ▁now ▁a ▁museum ▁) ▁in ▁P ▁un t ▁a ▁, ▁ < ▁unk ▁ > ▁. ▁ < ▁unk ▁ > ▁.\n",
            "pred text:  ▁city ▁, ▁including ▁its ▁very ▁first ▁chapel ▁( ▁now ▁a ▁museum ▁) ▁in ▁P ▁un t ▁a ▁, ▁ < ▁unk ▁ > ▁. ▁ < ▁unk ▁ > ▁,\n",
            "\n",
            "batch text:  ▁accident ▁was ▁too ▁real ▁. ▁Wagner ▁stated ▁the ▁film ▁had ▁sufficient ▁action ▁and ▁path ▁o s ▁without ▁sexual ▁ < ▁unk ▁ > ▁; ▁which ▁should ▁prove ▁a ▁strong ▁program\n",
            "true text:  ▁was ▁too ▁real ▁. ▁Wagner ▁stated ▁the ▁film ▁had ▁sufficient ▁action ▁and ▁path ▁o s ▁without ▁sexual ▁ < ▁unk ▁ > ▁; ▁which ▁should ▁prove ▁a ▁strong ▁program ▁for\n",
            "pred text:  ▁was ▁too ▁real ▁. ▁Wagner ▁stated ▁the ▁film ▁had ▁sufficient ▁action ▁and ▁path ▁o s ▁without ▁sexual ▁ < ▁unk ▁ > ▁; ▁which ▁should ▁prove ▁a ▁strong ▁program ▁he\n",
            "\n",
            "batch text:  ▁Beijing ▁games ▁) ▁, ▁at ▁least ▁one ▁woman ▁has ▁been ▁a ▁part ▁of ▁the ▁ < ▁unk ▁ > ▁deleg ▁at ion ▁. ▁The ▁smallest ▁ < ▁unk ▁ >\n",
            "true text:  ▁games ▁) ▁, ▁at ▁least ▁one ▁woman ▁has ▁been ▁a ▁part ▁of ▁the ▁ < ▁unk ▁ > ▁deleg ▁at ion ▁. ▁The ▁smallest ▁ < ▁unk ▁ > ▁of\n",
            "pred text:  ▁games ▁) ▁, ▁at ▁least ▁one ▁woman ▁has ▁been ▁a ▁part ▁of ▁the ▁ < ▁unk ▁ > ▁deleg ▁at ion ▁. ▁The ▁smallest ▁ < ▁unk ▁ > ▁.\n",
            "\n",
            "batch text:  ▁Airlines ▁( ▁ < ▁unk ▁ > ▁) ▁, ▁Air ▁Asia ▁, ▁and ▁ < ▁unk ▁ > ▁, ▁connecting ▁to ▁domestic ▁dest ▁in ations ▁such ▁as ▁: ▁ <\n",
            "true text:  ▁( ▁ < ▁unk ▁ > ▁) ▁, ▁Air ▁Asia ▁, ▁and ▁ < ▁unk ▁ > ▁, ▁connecting ▁to ▁domestic ▁dest ▁in ations ▁such ▁as ▁: ▁ < ▁unk\n",
            "pred text:  ▁( ▁ < ▁unk ▁ > ▁) ▁, ▁Air ▁Asia ▁, ▁and ▁ < ▁unk ▁ > ▁, ▁connecting ▁to ▁domestic ▁dest ▁in ations ▁such ▁as ▁: ▁ < e\n",
            "\n",
            "batch text:  < e os > ▁ < e os > ▁ < e os > ▁= ▁New ▁York ▁State ▁Route ▁93 ▁= ▁ < e os > ▁ < e os\n",
            "true text:  e os > ▁ < e os > ▁ < e os > ▁= ▁New ▁York ▁State ▁Route ▁93 ▁= ▁ < e os > ▁ < e os >\n",
            "pred text:  e os > ▁ < e os > ▁ < e os > ▁= ▁New ▁York ▁State ▁Route ▁93 ▁= ▁ < e os > ▁ < e os >\n",
            "\n",
            "batch text:  ▁ < ▁unk ▁ > ▁@ ▁, ▁@ ▁000 ▁casualties ▁were ▁registered ▁as ▁having ▁no ▁known ▁grave ▁. ▁ < e os > ▁The ▁scale ▁, ▁and ▁associated ▁high ▁number\n",
            "true text:  < ▁unk ▁ > ▁@ ▁, ▁@ ▁000 ▁casualties ▁were ▁registered ▁as ▁having ▁no ▁known ▁grave ▁. ▁ < e os > ▁The ▁scale ▁, ▁and ▁associated ▁high ▁number ▁of\n",
            "pred text:  < ▁unk ▁ > ▁@ ▁, ▁@ ▁000 ▁casualties ▁were ▁registered ▁as ▁having ▁no ▁known ▁grave ▁. ▁ < e os > ▁The ▁scale ▁, ▁and ▁associated ▁high ▁number ▁seven\n",
            "\n",
            "batch text:  ▁completed ▁. ▁ < e os > ▁ < e os > ▁= ▁= ▁Service ▁= ▁= ▁ < e os > ▁ < e os > ▁During ▁their ▁trials\n",
            "true text:  ▁. ▁ < e os > ▁ < e os > ▁= ▁= ▁Service ▁= ▁= ▁ < e os > ▁ < e os > ▁During ▁their ▁trials ▁the\n",
            "pred text:  ▁. ▁ < e os > ▁ < e os > ▁= ▁= ▁Service ▁= ▁= ▁ < e os > ▁ < e os > ▁During ▁their ▁trials ▁as\n",
            "\n",
            "batch text:  os > ▁ < e os > ▁= ▁= ▁Early ▁career ▁= ▁= ▁ < e os > ▁ < e os > ▁ < e os > ▁= ▁=\n",
            "true text:  > ▁ < e os > ▁= ▁= ▁Early ▁career ▁= ▁= ▁ < e os > ▁ < e os > ▁ < e os > ▁= ▁= ▁=\n",
            "pred text:  > ▁ < e os > ▁= ▁= ▁Early ▁career ▁= ▁= ▁ < e os > ▁ < e os > ▁ < e os > ▁= ▁= ▁=\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FI9xxruMHyd3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tt.save(model.state_dict(), 'model_state.tt')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "knwLgzl3zhSQ",
        "colab_type": "text"
      },
      "source": [
        "## Model Inference"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8eUIvfDcIckU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "infer_model = MyModel(len(TEXT.vocab.itos), len(TEXT.vocab.itos), 100, 128)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hH5HcXfyI1Xj",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        },
        "outputId": "fbe25bdf-e18f-41f6-d926-ff1b2d0e7793"
      },
      "source": [
        "infer_model.load_state_dict(tt.load('model_state.tt'))\n",
        "infer_model.eval()"
      ],
      "execution_count": 265,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "MyModel(\n",
              "  (embedding): Embedding(12202, 100)\n",
              "  (rnn): LSTM(100, 128, bidirectional=True)\n",
              "  (fc): Linear(in_features=256, out_features=12202, bias=True)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 265
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KHgm0FFthkpY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from math import log\n",
        "from numpy import array\n",
        "from numpy import argmax\n",
        " \n",
        "# beam search\n",
        "def beam_search_decoder(data):\n",
        "  sequences = [[list(), 1.0]]\n",
        "\t# walk over each step in sequence\n",
        "  for row in data:\n",
        "    all_candidates = list()\n",
        "\t\t# expand each current candidate\n",
        "    for i in range(len(sequences)):\n",
        "      seq, score = sequences[i]\n",
        "      for j in range(len(row)):\n",
        "        candidate = [seq + [j], score * -log(row[j])]\n",
        "        all_candidates.append(candidate)\n",
        "\t\t# order all candidates by score\n",
        "    ordered = sorted(all_candidates, key=lambda tup:tup[1])\n",
        "    # select k best\n",
        "  # print(ordered)\n",
        "  sequences = ordered[:1]\n",
        "  pred = sequences[0][0][0]\n",
        "  return pred\n",
        "\n",
        "# code source: https://machinelearningmastery.com/beam-search-decoder-natural-language-processing/"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vBoy3QDHZdZB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def generate_text(model, function_name, input_str):\n",
        "  generated = input_str\n",
        "  input_tns = TEXT.process(TEXT.preprocess(input_str))\n",
        "\n",
        "  for _ in tqdm(range(30)):\n",
        "    pred = tt.softmax(model(input_tns), dim=1)\n",
        "    \n",
        "    if function_name == 'argmax':\n",
        "      pred = tt.argmax(pred, dim=1)\n",
        "      input_tns = pred\n",
        "      output_list = [[TEXT.vocab.itos[i.item()] for i in piece] for piece in input_tns.transpose(1,0)]\n",
        "      output = [item for item in output_list]    \n",
        "    elif function_name == 'beam':\n",
        "      pred = [beam_search_decoder(item) for item in pred]\n",
        "      char = TEXT.vocab.itos[pred[-1]]\n",
        "      input_tns = TEXT.process(TEXT.preprocess(char))\n",
        "      output_list = [[char]]\n",
        "  \n",
        "    generated += output_list[-1][-1]\n",
        "  return generated.replace('▁', ' ')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9LI4HAinvzko",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "a6fc9d81-79d0-4337-c905-65448a7bb853"
      },
      "source": [
        "generate_text(infer_model, 'beam', 'My')"
      ],
      "execution_count": 406,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 30/30 [00:22<00:00,  1.22it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'My UNK <pad> the UNK <pad> the UNK <pad> the UNK <pad> the UNK <pad> the UNK <pad> the UNK <pad> the UNK <pad> the UNK <pad> the UNK <pad> the'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 406
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ofxfQDx7hlUG",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "6d3f027a-6b59-4b7b-b074-fa1e1ad54061"
      },
      "source": [
        "generate_text(infer_model, 'argmax', 'My')"
      ],
      "execution_count": 407,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 30/30 [00:00<00:00, 333.67it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'My . The diplom is a < unk > , and < unk > , and < unk > , and < unk '"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 407
        }
      ]
    }
  ]
}