{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6"
    },
    "colab": {
      "name": "exam_var2.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/eischaire/ML_4year/blob/master/exam_var2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pB9N2RGb208u",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# !wget https://github.com/thedenaas/hse_seminars/raw/master/2019/exam/exam_data.zip"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i6dfCjBe3Pu1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# !unzip exam_data.zip\n",
        "# !ls"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IHRnoXxZ2lOi",
        "colab_type": "text"
      },
      "source": [
        "# Exam\n",
        "\n",
        "Develop a model for predicting review rating.  \n",
        "**Binary classification:**  \n",
        "**positive class: target = 5**   \n",
        "**negative class: target = 1,2,3,4**  \n",
        "Score: **binary F1**  \n",
        "You are forbidden to use test dataset for any kind of training.  \n",
        "Remember proper training pipeline.  \n",
        "If you are not using default params in the models, you have to use some validation scheme to justify them. \n",
        "\n",
        "Use `random_state` or `seed` params - your experiment must be reprodusible.\n",
        "\n",
        "\n",
        "### 1 baseline = 0.720\n",
        "### 2 baseline = 0.745\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RFiws1mKPt-f",
        "colab_type": "text"
      },
      "source": [
        "## Answer for the theoretical question\n",
        "\n",
        "### Question â„–10. Discrepancy in seq2seq model training and inference implementation\n",
        "\n",
        "The problem is that during training, true previous token is taken as the input for a model, whilst on the inference phase the teacher forcing is used, i.e. a previously predicted token becomes the input on every following iteration. \n",
        "\n",
        "So, the model functions differently in training and inference phases. The train task is easier, as every iteration contains true previous information. During the inference, we cannot guarantee that the information in the input is 'true' or 'good', and generation here is riskier."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H8VIPBYd2lOt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from gensim.models.word2vec import Word2Vec\n",
        "from sklearn.base import TransformerMixin\n",
        "from sklearn.metrics import f1_score\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import re\n",
        "from warnings import filterwarnings\n",
        "filterwarnings('ignore')\n",
        "SEED = 4242"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TkgF95_52lPO",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "ce2bf804-f5e9-48cb-8b94-aaa193bcf252"
      },
      "source": [
        "df_train = pd.read_csv('train.csv')\n",
        "df_test = pd.read_csv('test.csv')\n",
        "\n",
        "df_train['target'] = (df_train['target'] == 5).astype(np.int)\n",
        "df_test['target'] = (df_test['target'] == 5).astype(np.int)\n",
        "\n",
        "df_train.shape"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(48192, 3)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vFptN4jo3x_Y",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "73e85e85-1fee-4dbc-86d5-0493240abad0"
      },
      "source": [
        "df_train.head()"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>review</th>\n",
              "      <th>title</th>\n",
              "      <th>target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>The staff was very friendly, the breakfast ver...</td>\n",
              "      <td>Walker Gem</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Excellent service - very approachable and prof...</td>\n",
              "      <td>Excellent Service</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Really a top notch place to spend a day at the...</td>\n",
              "      <td>Good location, warm and friendly staff</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>a little noisy, there was a false fire alarm a...</td>\n",
              "      <td>nice hotel,</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Place had too many animals and I'm allergic to...</td>\n",
              "      <td>Experience</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                              review  ... target\n",
              "0  The staff was very friendly, the breakfast ver...  ...      1\n",
              "1  Excellent service - very approachable and prof...  ...      0\n",
              "2  Really a top notch place to spend a day at the...  ...      1\n",
              "3  a little noisy, there was a false fire alarm a...  ...      0\n",
              "4  Place had too many animals and I'm allergic to...  ...      0\n",
              "\n",
              "[5 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hnLDykBg5F2i",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# code from a seminar notebook\n",
        "\n",
        "class Word2VecWrapper(TransformerMixin):\n",
        "    def __init__(self, window=5,negative=5, size=100, iter=100, is_cbow=False, random_state=SEED):\n",
        "        self.window_ = window\n",
        "        self.negative_ = negative\n",
        "        self.size_ = size\n",
        "        self.iter_ = iter\n",
        "        self.is_cbow_ = is_cbow\n",
        "        self.w2v = None\n",
        "        self.random_state = random_state\n",
        "        \n",
        "    def get_size(self):\n",
        "        return self.size_\n",
        "\n",
        "    def fit(self, X, y=None):\n",
        "        \"\"\"\n",
        "        X: list of strings\n",
        "        \"\"\"\n",
        "        sentences_list = [x.split() for x in X]\n",
        "        self.w2v = Word2Vec(sentences_list, \n",
        "                            window=self.window_,\n",
        "                            negative=self.negative_, \n",
        "                            size=self.size_, \n",
        "                            iter=self.iter_,\n",
        "                            sg=not self.is_cbow_, seed=self.random_state)\n",
        "\n",
        "        return self\n",
        "    \n",
        "    def has(self, word):\n",
        "        return word in self.w2v\n",
        "\n",
        "    def transform(self, X):\n",
        "        \"\"\"\n",
        "        X: a list of words\n",
        "        \"\"\"\n",
        "        if self.w2v is None:\n",
        "            raise Exception('model not fitted')\n",
        "        return np.array([self.w2v[w] if w in self.w2v else np.zeros(self.size_) for w in X ])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HNtLVU_I5sdI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "a34f4228-a4df-4b13-8d6c-5238474f1ae5"
      },
      "source": [
        "%%time\n",
        "reviews_list = [re.sub('  ', ' ', re.sub('\\n', ' ', x.strip())) for x in df_train.review]\n",
        "# titles_list = [re.sub('  ', ' ', re.sub('\\n', ' ', x.strip())) for x in df_train.title]\n",
        "\n",
        "w2v_cbow = Word2VecWrapper(window=5, negative=5, size=300, iter=300, is_cbow=True, random_state=SEED)\n",
        "w2v_cbow.fit(reviews_list[:15000])\n",
        "\n",
        "vectorized_reviews = [np.mean(w2v_cbow.transform(sentence.split(' ')), axis=0) for sentence in reviews_list]\n",
        "df_train['vectorized_review'] = pd.Series(vectorized_reviews)\n",
        "\n",
        "# vectorized_title = [np.mean(w2v_cbow.transform(sentence.split(' ')), axis=0) for sentence in titles_list]\n",
        "# df_train['vectorized_title'] = pd.Series(vectorized_title)\n",
        "\n",
        "test_reviews = [re.sub('  ', ' ', re.sub('\\n', ' ', x.strip())) for x in df_test.review]\n",
        "df_test['vectorized_review'] = pd.Series([np.mean(w2v_cbow.transform(sentence.split(' ')), axis=0) for sentence in test_reviews])\n"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 14min 53s, sys: 3.33 s, total: 14min 56s\n",
            "Wall time: 7min 53s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C9m9vwc0EIuQ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "0d1ff1c8-ae8b-4f84-fdfb-8ae4b111899b"
      },
      "source": [
        "trial_xtrain = list(df_train['vectorized_review'])\n",
        "trial_ytrain = list(df_train['target'])\n",
        "trial_xtest = list(df_test['vectorized_review'])\n",
        "trial_ytest = list(df_test['target'])"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 17.4 ms, sys: 6.9 ms, total: 24.3 ms\n",
            "Wall time: 24.1 ms\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2fHW2hAbMJnu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%%time\n",
        "knn = KNeighborsClassifier(n_neighbors=10, metric='cosine')\n",
        "knn.fit(trial_xtrain, trial_ytrain)\n",
        "y_pred = knn.predict(trial_xtest)\n",
        "print(f1_score(trial_ytest, y_pred))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SLFZGh-lnfOy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}